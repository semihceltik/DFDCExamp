# -*- coding: utf-8 -*-
"""DeepFakeDetectionEnesAYAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L2tmFNlUJafk-3RlRpPilFzdEzjNYYWt
"""

import tensorflow as tf
print("GPU kullanılabilirliği: ", tf.test.is_gpu_available())
!pip install transformers
import numpy as np
import pandas as pd
import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, GlobalAveragePooling2D, Lambda
from tensorflow.keras.models import Model
from transformers import TFViTModel
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')
data_path = '/content/drive/MyDrive/KaggleDataSets/celeb-df.zip'

base_path = '/content/drive/MyDrive/KaggleDataSets/celeb-df_extracted/celeb-df'
train_path = os.path.join(base_path,'train ')
test_path  = os.path.join(base_path,'test')
val_path = os.path.join(base_path,'validation')

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    shuffle = True
)
val_generator = val_datagen.flow_from_directory(
    val_path,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    shuffle = False
)
test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=(224,224),
    batch_size=32,
    class_mode='binary',
    shuffle = False
)

print(f"Training Samples:{train_generator.samples}")
print(f"Validation Samples:{val_generator.samples}")
print(f"Test Generator Samples: {test_generator.samples}")
print(f"Sınıf Indeksleri", train_generator.class_indices)

vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in vgg16_base.layers:
    layer.trainable = False
vgg16_output = vgg16_base.output
vgg16_output = GlobalAveragePooling2D()(vgg16_output)

vit_model = TFViTModel.from_pretrained('google/vit-base-patch16-224')
vit_input = Input(shape=(224, 224, 3))
vit_transposed = Lambda(lambda x: tf.transpose(x, perm=[0, 3, 1, 2]))(vit_input)
vit_output = Lambda(lambda x: vit_model(x).last_hidden_state[:, 0, :], output_shape=(768,))(vit_transposed)

combined = Concatenate()([vgg16_output, vit_output])
x = Dense(128, activation='relu')(combined)
x = Dense(1, activation='sigmoid')(x)

model = Model(inputs=[vgg16_base.input, vit_input], outputs=x)

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

def custom_generator(generator):
    while True:
        images, labels = next(generator)
        yield (images, images), labels

train_dataset = tf.data.Dataset.from_generator(
    lambda: custom_generator(train_generator),
    output_signature=(
        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),
        tf.TensorSpec(shape=(None,), dtype=tf.float32)
    )
)

val_dataset = tf.data.Dataset.from_generator(
    lambda: custom_generator(val_generator),
    output_signature=(
        (tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),
         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)),
        tf.TensorSpec(shape=(None,), dtype=tf.float32)
    )
)

print(model.input)

history = model.fit(
    train_dataset,
    epochs=10,
    validation_data=val_dataset,
    steps_per_epoch=train_generator.samples // 32,
    validation_steps=val_generator.samples // 32
)

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

test_loss, test_accuracy = model.evaluate([test_generator, test_generator])
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")